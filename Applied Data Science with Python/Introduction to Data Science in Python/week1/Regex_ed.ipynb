{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex\n",
    "\n",
    "In this lecture we're going to talk about pattern matching in strings using regular expressions. Regular expressions, or regexes, are written in a condensed formatting language. In general, you can think of a regular expression as a pattern which you give to a regex processor with some source data. The processor then parses that source data using that pattern, and returns chunks of text back to the a data scientist or  programmer for further manipulation. There's really three main reasons you would want to do this - to check whether a pattern exists within some source data, to get all instances of a complex pattern from some source data, or to clean your source data using a pattern generally through string splitting. Regexes are not trivial, but they are a foundational technique for data cleaning in data science applications, and a solid understanding of regexs will help you quickly and efficiently manipulate text data for further data science application.\n",
    "\n",
    "Now, you could teach a whole course on regular expressions alone, especially if you wanted to demystify how the regex parsing engine works and efficient mechanisms for parsing text. In this lecture I want to give you basic understanding of how regex works - enough knowledge that, with a little directed sleuthing, you'll be able to make sense of the regex patterns you see others use, and you can build up your practical knowledge of how to use regexes to improve your data cleaning. By the end of this lecture, you will understand the basics of regular expressions, how to define patterns for matching, how to apply these patterns to strings, and how to use the results of those patterns in data processing.\n",
    "\n",
    "Finally, a note that in order to best learn regexes you need to write regexes. I encourage you to stop the video at any time and try out new patterns or syntax you learn at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we'll import the re module, which is where python stores regular expression libraries.\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wonderful!\n"
     ]
    }
   ],
   "source": [
    "# There are several main processing functions in re that you might use. The first, match() checks for a match\n",
    "# that is at the beginning of the string and returns a boolean. Similarly, search(), checks for a match\n",
    "# anywhere in the string, and returns a boolean.\n",
    "\n",
    "# Lets create some text for an example\n",
    "text = \"This is a good day.\"\n",
    "\n",
    "# Now, lets see if it's a good day or not:\n",
    "if re.search(\"good\", text): # the first parameter here is the pattern\n",
    "    print(\"Wonderful!\")\n",
    "else:\n",
    "    print(\"Alas :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " ' works diligently. ',\n",
       " ' gets good grades. Our student ',\n",
       " ' is succesful.']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In addition to checking for conditionals, we can segment a string. The work that regex does here is called\n",
    "# tokenizing, where the string is separated into substrings based on patterns. Tokenizing is a core activity\n",
    "# in natural language processing, which we won't talk much about here but that you will study in the future\n",
    "\n",
    "# The findall() and split() functions will parse the string for us and return chunks. Lets try and example\n",
    "text = \"Amy works diligently. Amy gets good grades. Our student Amy is succesful.\"\n",
    "\n",
    "# This is a bit of a fabricated example, but lets split this on all instances of Amy\n",
    "re.split(\"Amy\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amy', 'Amy', 'Amy']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You'll notice that split has returned an empty string, followed by a number of statements about Amy, all as\n",
    "# elements of a list. If we wanted to count how many times we have talked about Amy, we could use findall()\n",
    "re.findall(\"Amy\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, so we've seen that .search() looks for some pattern and returns a boolean, that .split() will use a\n",
    "# pattern for creating a list of substrings, and that .findall() will look for a pattern and pull out all\n",
    "# occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='Amy'>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we know how the python regex API works, lets talk about more complex patterns. The regex\n",
    "# specification standard defines a markup language to describe patterns in text. Lets start with anchors.\n",
    "# Anchors specify the start and/or the end of the string that you are trying to match. The caret character ^\n",
    "# means start and the dollar sign character $ means end. If you put ^ before a string, it means that the text\n",
    "# the regex processor retrieves must start with the string you specify. For ending, you have to put the $\n",
    "# character after the string, it means that the text Regex retrieves must end with the string you specify.\n",
    "\n",
    "# Here's an example\n",
    "text = \"Amy works diligently. Amy gets good grades. Our student Amy is succesful.\"\n",
    "\n",
    "# Lets see if this begins with Amy\n",
    "re.search(\"^Amy\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that re.search() actually returned to us a new object, called re.Match object. An re.Match object\n",
    "# always has a boolean value of True, as something was found, so you can always evaluate it in an if statement\n",
    "# as we did earlier. The rendering of the match object also tells you what pattern was matched, in this case\n",
    "# the word Amy, and the location the match was in, as the span."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patterns and Character Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'B', 'B']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's talk more about patterns and start with character classes. Let's create a string of a single learners'\n",
    "# grades over a semester in one course across all of their assignments\n",
    "grades=\"ACAAAABCBCBAA\"\n",
    "\n",
    "# If we want to answer the question \"How many B's were in the grade list?\" we would just use B\n",
    "re.findall(\"B\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'A', 'A']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we wanted to count the number of A's or B's in the list, we can't use \"AB\" since this is used to match\n",
    "# all A's followed immediately by a B. Instead, we put the characters A and B inside square brackets\n",
    "re.findall(\"[AB]\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AC', 'AB']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is called the set operator. You can also include a range of characters, which are ordered\n",
    "# alphanumerically. For instance, if we want to refer to all lower case letters we could use [a-z] Lets build\n",
    "# a simple regex to parse out all instances where this student receive an A followed by a B or a C\n",
    "re.findall(\"[A][B-C]\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AC', 'AB']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice how the [AB] pattern describes a set of possible characters which could be either (A OR B), while the\n",
    "# [A][B-C] pattern denoted two sets of characters which must have been matched back to back. You can write\n",
    "# this pattern by using the pipe operator, which means OR\n",
    "re.findall(\"AB|AC\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C', 'B', 'C', 'B', 'C', 'B']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the caret with the set operator to negate our results. For instance, if we want to parse out only\n",
    "# the grades which were not A's\n",
    "re.findall(\"[^A]\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note this carefully - the caret was previously matched to the beginning of a string as an anchor point, but\n",
    "# inside of the set operator the caret, and the other special characters we will be talking about, lose their\n",
    "# meaning. This can be a bit confusing. What do you think the result would be of this?\n",
    "re.findall(\"^[^A]\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's an empty list, because the regex says that we want to match any value at the beginning of the string\n",
    "# which is not an A. Our string though starts with an A, so there is no match found. And remember when you are\n",
    "# using the set operator you are doing character-based matching. So you are matching individual characters in\n",
    "# an OR method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, so we've talked about anchors and matching to the beginning and end of patterns. And we've talked about\n",
    "# characters and using sets with the [] notation. We've also talked about character negation, and how the pipe\n",
    "# | character allows us to or operations. Lets move on to quantifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAAA', 'AA']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantifiers are the number of times you want a pattern to be matched in order to match. The most basic\n",
    "# quantifier is expressed as e{m,n}, where e is the expression or character we are matching, m is the minimum\n",
    "# number of times you want it to matched, and n is the maximum number of times the item could be matched.\n",
    "\n",
    "# Let's use these grades as an example. How many times has this student been on a back-to-back A's streak?\n",
    "re.findall(\"A{2,10}\",grades) # we'll use 2 as our min, but ten as our max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'AA', 'AA']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we see that there were two streaks, one where the student had four A's, and one where they had only two\n",
    "# A's\n",
    "\n",
    "# We might try and do this using single values and just repeating the pattern\n",
    "re.findall(\"A{1,1}A{1,1}\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As you can see, this is different than the first example. The first pattern is looking for any combination\n",
    "# of two A's up to ten A's in a row. So it sees four A's as a single streak. The second pattern is looking for\n",
    "# two A's back to back, so it sees two A's followed immediately by two more A's. We say that the regex\n",
    "# processor begins at the start of the string and consumes variables which match patterns as it does.\n",
    "\n",
    "# It's important to note that the regex quantifier syntax does not allow you to deviate from the {m,n}\n",
    "# pattern. In particular, if you have an extra space in between the braces you'll get an empty result\n",
    "re.findall(\"A{2, 2}\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'AA', 'AA']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And as we have already seen, if we don't include a quantifier then the default is {1,1}\n",
    "re.findall(\"AA\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'AA', 'AA']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oh, and if you just have one number in the braces, it's considered to be both m and n\n",
    "re.findall(\"A{2}\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAAABC']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using this, we could find a decreasing trend in a student's grades\n",
    "re.findall(\"A{1,10}B{1,10}C{1,10}\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Overview[edit]\\nFERPA gives parents access to their child\\'s education records, an opportunity to seek to have the records amended, and some control over the disclosure of information from the records. With several exceptions, schools must have a student\\'s consent prior to the disclosure of education records after that student is 18 years old. The law applies only to educational agencies and institutions that receive funds under a program administered by the U.S. Department of Education.\\n\\nOther regulations under this act, effective starting January 3, 2012, allow for greater disclosures of personal and directory student identifying information and regulate student IDs and e-mail addresses.[2] For example, schools may provide external companies with a student\\'s personally identifiable information without the student\\'s consent.[2]\\n\\nExamples of situations affected by FERPA include school employees divulging information to anyone other than the student about the student\\'s grades or behavior, and school work posted on a bulletin board with a grade. Generally, schools must have written permission from the parent or eligible student in order to release any information from a student\\'s education record.\\n\\nThis privacy policy also governs how state agencies transmit testing data to federal agencies, such as the Education Data Exchange Network.\\n\\nThis U.S. federal law also gave students 18 years of age or older, or students of any age if enrolled in any post-secondary educational institution, the right of privacy regarding grades, enrollment, and even billing information unless the school has specific permission from the student to share that specific type of information.\\n\\nFERPA also permits a school to disclose personally identifiable information from education records of an \"eligible student\" (a student age 18 or older or enrolled in a postsecondary institution at any age) to his or her parents if the student is a \"dependent student\" as that term is defined in Section 152 of the Internal Revenue Code. Generally, if either parent has claimed the student as a dependent on the parent\\'s most recent income tax statement, the school may non-consensually disclose the student\\'s education records to both parents.[3]\\n\\nThe law allowed students who apply to an educational institution such as graduate school permission to view recommendations submitted by others as part of the application. However, on standard application forms, students are given the option to waive this right.\\n\\nFERPA specifically excludes employees of an educational institution if they are not students.\\n\\nThe act is also referred to as the Buckley Amendment, for one of its proponents, Senator James L. Buckley of New York.\\n\\nAccess to public records[edit]\\nThe citing of FERPA to conceal public records that are not \"educational\" in nature has been widely criticized, including by the act\\'s primary Senate sponsor.[4] For example, in the Owasso Independent School District v. Falvo case, an important part of the debate was determining the relationship between peer-grading and \"education records\" as defined in FERPA. In the Court of Appeals, it was ruled that students placing grades on the work of other students made such work into an \"education record.\" Thus, peer-grading was determined as a violation of FERPA privacy policies because students had access to other students\\' academic performance without full consent.[5] However, when the case went to the Supreme Court, it was officially ruled that peer-grading was not a violation of FERPA. This is because a grade written on a student\\'s work does not become an \"education record\" until the teacher writes the final grade into a grade book.[6]\\n\\nStudent medical records[edit]\\nLegal experts have debated the issue of whether student medical records (for example records of therapy sessions with a therapist at an on-campus counseling center) might be released to the school administration under certain triggering events, such as when a student sued his college or university.[7][8]\\n\\nUsually, student medical treatment records will remain under the protection of FERPA, not the Health Insurance Portability and Accountability Act (HIPAA). This is due to the \"FERPA Exception\" written within HIPAA.[9]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, that's a bit of a hack, because we included a maximum that was just arbitrarily large. There are three\n",
    "# other quantifiers that are used as short hand, an asterix * to match 0 or more times, a question mark ? to\n",
    "# match one or more times, or a + plus sign to match one or more times. Lets look at a more complex example,\n",
    "# and load some data scraped from wikipedia\n",
    "with open(\"ferpa.txt\",\"r\") as file:\n",
    "    # we'll read that into a variable called wiki\n",
    "    wiki=file.read()\n",
    "# and lets print that variable out to the screen\n",
    "wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Overview[edit]', 'records[edit]', 'records[edit]']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scanning through this document one of the things we notice is that the headers all have the words [edit]\n",
    "# behind them, followed by a newline character. So if we wanted to get a list of all of the headers in this\n",
    "# article we could do so using re.findall\n",
    "re.findall(\"[a-zA-Z]{1,100}\\[edit\\]\",wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Overview[edit]', 'records[edit]', 'records[edit]']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ok, that didn't quite work. It got all of the headers, but only the last word of the header, and it really\n",
    "# was quite clunky. Lets iteratively improve this. First, we can use \\w to match any letter, including digits\n",
    "# and numbers.\n",
    "re.findall(\"[\\w]{1,100}\\[edit\\]\",wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Overview[edit]', 'records[edit]', 'records[edit]']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is something new. \\w is a metacharacter, and indicates a special pattern of any letter or digit. There\n",
    "# are actually a number of different metacharacters listed in the documentation. For instance, \\s matches any\n",
    "# whitespace character.\n",
    "\n",
    "# Next, there are three other quantifiers we can use which shorten up the curly brace syntax. We can use an\n",
    "# asterix * to match 0 or more times, so let's try that.\n",
    "re.findall(\"[\\w]*\\[edit\\]\",wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Overview[edit]',\n",
       " 'Access to public records[edit]',\n",
       " 'Student medical records[edit]']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have shortened the regex, let's improve it a little bit. We can add in a spaces using the space\n",
    "# character\n",
    "re.findall(\"[\\w ]*\\[edit\\]\",wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview\n",
      "Access to public records\n",
      "Student medical records\n"
     ]
    }
   ],
   "source": [
    "# Ok, so this gets us the list of section titles in the wikipedia page! You can now create a list of titles by\n",
    "# iterating through this and applying another regex\n",
    "for title in re.findall(\"[\\w ]*\\[edit\\]\",wiki):\n",
    "    # Now we will take that intermediate result and split on the square bracket [ just taking the first result\n",
    "    print(re.split(\"[\\[]\",title)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Overview', '[edit]'),\n",
       " ('Access to public records', '[edit]'),\n",
       " ('Student medical records', '[edit]')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ok, this works, but it's a bit of a pain. To this point we have been talking about a regex as a single\n",
    "# pattern which is matched. But, you can actually match different patterns, called groups, at the same time,\n",
    "# and then refer to the groups you want. To group patterns together you use parentheses, which is actually\n",
    "# pretty natural. Lets rewrite our findall using groups\n",
    "re.findall(\"([\\w ]*)(\\[edit\\])\",wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overview', '[edit]')\n",
      "('Access to public records', '[edit]')\n",
      "('Student medical records', '[edit]')\n"
     ]
    }
   ],
   "source": [
    "# Nice - we see that the python re module breaks out the result by group. We can actually refer to groups by\n",
    "# number as well with the match objects that are returned. But, how do we get back a list of match objects?\n",
    "# Thus far we've seen that findall() returns strings, and search() and match() return individual Match\n",
    "# objects. But what do we do if we want a list of Match objects? In this case, we use the function finditer()\n",
    "for item in re.finditer(\"([\\w ]*)(\\[edit\\])\",wiki):\n",
    "    print(item.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview\n",
      "Access to public records\n",
      "Student medical records\n"
     ]
    }
   ],
   "source": [
    "# We see here that the groups() method returns a tuple of the group. We can get an individual group using\n",
    "# group(number), where group(0) is the whole match, and each other number is the portion of the match we are\n",
    "# interested in. In this case, we want group(1)\n",
    "for item in re.finditer(\"([\\w ]*)(\\[edit\\])\",wiki):\n",
    "    print(item.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview\n",
      "Access to public records\n",
      "Student medical records\n"
     ]
    }
   ],
   "source": [
    "# One more piece to regex groups that I rarely use but is a good idea is labeling or naming groups. In the\n",
    "# previous example I showed you how you can use the position of the group. But giving them a label and looking\n",
    "# at the results as a dictionary is pretty useful. For that we use the syntax (?P<name>), where the parethesis\n",
    "# starts the group, the ?P indicates that this is an extension to basic regexes, and <name> is the dictionary\n",
    "# key we want to use wrapped in <>.\n",
    "for item in re.finditer(\"(?P<title>[\\w ]*)(?P<edit_link>\\[edit\\])\",wiki):\n",
    "    # We can get the dictionary returned for the item with .groupdict()\n",
    "    print(item.groupdict()['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Student medical records', 'edit_link': '[edit]'}\n"
     ]
    }
   ],
   "source": [
    "# Of course, we can print out the whole dictionary for the item too, and see that the [edit] string is still\n",
    "# in there. Here's the dictionary kept for the last match\n",
    "print(item.groupdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, we have seen how we can match individual character patterns with [], how we can group matches together\n",
    "# using (), and how we can use quantifiers such as *, ?, or m{n} to describe patterns. Something I glossed\n",
    "# over in the previous example was the \\w, which standards for any word character. There are a number of\n",
    "# short hands which are used with regexes for different kinds of characters, including:\n",
    "# a . for any single character which is not a newline\n",
    "# a \\d for any digit\n",
    "# and \\s for any whitespace character, like spaces and tabs\n",
    "# There are more, and a full list can be found in the python documentation for regexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look-ahead and Look-behind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 8), match='Overview'>\n",
      "<re.Match object; span=(2715, 2739), match='Access to public records'>\n",
      "<re.Match object; span=(3692, 3715), match='Student medical records'>\n"
     ]
    }
   ],
   "source": [
    "# One more concept to be familiar with is called \"look ahead\" and \"look behind\" matching. In this case, the\n",
    "# pattern being given to the regex engine is for text either before or after the text we are trying to\n",
    "# isolate. For example, in our headers we want to isolate text which  comes before the [edit] rendering, but\n",
    "# we actually don't care about the [edit] text itself. Thus far we have been throwing the [edit] away, but if\n",
    "# we want to use them to match but don't want to capture them we could put them in a group and use look ahead\n",
    "# instead with ?= syntax\n",
    "for item in re.finditer(\"(?P<title>[\\w ]+)(?=\\[edit\\])\",wiki):\n",
    "    # What this regex says is match two groups, the first will be named and called title, will have any amount\n",
    "    # of whitespace or regular word characters, the second will be the characters [edit] but we don't actually\n",
    "    # want this edit put in our output match objects\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Wikipedia Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Buddhist universities and colleges in the United States\\nFrom Wikipedia, the free encyclopedia\\nJump to navigationJump to search\\n\\nThis article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.\\nFind sources: \"Buddhist universities and colleges in the United States\" \\xe2\\x80\\x93 news \\xc2\\xb7 newspapers \\xc2\\xb7 books \\xc2\\xb7 scholar \\xc2\\xb7 JSTOR (December 2009) (Learn how and when to remove this template message)\\nThere are several Buddhist universities in the United States. Some of these have existed for decades and are accredited. Others are relatively new and are either in the process of being accredited or else have no formal accreditation. The list includes:\\n\\nDhammakaya Open University \\xe2\\x80\\x93 located in Azusa, California, part of the Thai Wat Phra Dhammakaya[1]\\nDharmakirti College \\xe2\\x80\\x93 located in Tucson, Arizona Now called Awam Tibetan Buddhist Institute (http://awaminstitute.org/)\\nDharma Realm Buddhist University \\xe2\\x80\\x93 located in Ukiah, California\\nEwam Buddhist Institute \\xe2\\x80\\x93 located in Arlee, Montana\\nNaropa University is located in Boulder, Colorado (Accredited by the Higher Learning Commission)\\nInstitute of Buddhist Studies \\xe2\\x80\\x93 located in Berkeley, California\\nMaitripa College \\xe2\\x80\\x93 located in Portland, Oregon\\nSoka University of America \\xe2\\x80\\x93 located in Aliso Viejo, California\\nUniversity of the West \\xe2\\x80\\x93 located in Rosemead, California\\nWon Institute of Graduate Studies \\xe2\\x80\\x93 located in Glenside, Pennsylvania\\nReferences[edit]\\n^ Banchanon, Phongphiphat (3 February 2015). \\xe0\\xb8\\xa3\\xe0\\xb8\\xb9\\xe0\\xb9\\x89\\xe0\\xb8\\x88\\xe0\\xb8\\xb1\\xe0\\xb8\\x81 \"\\xe0\\xb9\\x80\\xe0\\xb8\\x84\\xe0\\xb8\\xa3\\xe0\\xb8\\xb7\\xe0\\xb8\\xad\\xe0\\xb8\\x82\\xe0\\xb9\\x88\\xe0\\xb8\\xb2\\xe0\\xb8\\xa2\\xe0\\xb8\\x98\\xe0\\xb8\\xa3\\xe0\\xb8\\xa3\\xe0\\xb8\\xa1\\xe0\\xb8\\x81\\xe0\\xb8\\xb2\\xe0\\xb8\\xa2\" [Getting to know the Dhammakaya network]. Forbes Thailand (in Thai). Retrieved 11 November 2016.\\nExternal links[edit]\\nList of Buddhist Universities and Colleges in the world\\n'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at some more wikipedia data. Here's some data on universities in the US which are buddhist-based\n",
    "with open(\"buddhist.txt\",\"rb\") as file:\n",
    "# we'll read that into a variable called wiki\n",
    "    wiki=file.read()\n",
    "# and lets print that variable out to the screen\n",
    "wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lishe\\Documents\\GitHub\\Python\\Applied_Data_Science_with_Python\\week1\\Regex_ed.ipynb Cell 42\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lishe/Documents/GitHub/Python/Applied_Data_Science_with_Python/week1/Regex_ed.ipynb#X56sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m pattern\u001b[39m=\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lishe/Documents/GitHub/Python/Applied_Data_Science_with_Python/week1/Regex_ed.ipynb#X56sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m(?P<title>.*)        #the university title\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lishe/Documents/GitHub/Python/Applied_Data_Science_with_Python/week1/Regex_ed.ipynb#X56sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m(_\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m located\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m in\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m )   #an indicator of the location\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lishe/Documents/GitHub/Python/Applied_Data_Science_with_Python/week1/Regex_ed.ipynb#X56sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m(?P<city>\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw*)        #city the university is in\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lishe/Documents/GitHub/Python/Applied_Data_Science_with_Python/week1/Regex_ed.ipynb#X56sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m(,\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m )                #separator for the state\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lishe/Documents/GitHub/Python/Applied_Data_Science_with_Python/week1/Regex_ed.ipynb#X56sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m(?P<state>\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw*)       #the state the city is located in\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lishe/Documents/GitHub/Python/Applied_Data_Science_with_Python/week1/Regex_ed.ipynb#X56sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Now when we call finditer() we just pass the re.VERBOSE flag as the last parameter, this makes it much\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lishe/Documents/GitHub/Python/Applied_Data_Science_with_Python/week1/Regex_ed.ipynb#X56sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# easier to understand large regexes!\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lishe/Documents/GitHub/Python/Applied_Data_Science_with_Python/week1/Regex_ed.ipynb#X56sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m re\u001b[39m.\u001b[39;49mfinditer(pattern,wiki,re\u001b[39m.\u001b[39;49mVERBOSE):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lishe/Documents/GitHub/Python/Applied_Data_Science_with_Python/week1/Regex_ed.ipynb#X56sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# We can get the dictionary returned for the item with .groupdict()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lishe/Documents/GitHub/Python/Applied_Data_Science_with_Python/week1/Regex_ed.ipynb#X56sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(item\u001b[39m.\u001b[39mgroupdict())\n",
      "File \u001b[1;32mc:\\Users\\lishe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\re\\__init__.py:223\u001b[0m, in \u001b[0;36mfinditer\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfinditer\u001b[39m(pattern, string, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m    219\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return an iterator over all non-overlapping matches in the\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[39m    string.  For each match, the iterator returns a Match object.\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \n\u001b[0;32m    222\u001b[0m \u001b[39m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\u001b[39m.\u001b[39;49mfinditer(string)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "# We can see that each university follows a fairly similar pattern, with the name followed by an – then the\n",
    "# words \"located in\" followed by the city and state\n",
    "\n",
    "# I'll actually use this example to show you the verbose mode of python regexes. The verbose mode allows you\n",
    "# to write multi-line regexes and increases readability. For this mode, we have to explicitly indicate all\n",
    "# whitespace characters, either by prepending them with a \\ or by using the \\s special value. However, this\n",
    "# means we can write our regex a bit more like code, and can even include comments with #\n",
    "pattern=\"\"\"\n",
    "(?P<title>.*)        #the university title\n",
    "(-\\ located\\ in\\ )   #an indicator of the location\n",
    "(?P<city>\\w*)        #city the university is in\n",
    "(,\\ )                #separator for the state\n",
    "(?P<state>\\w*)       #the state the city is located in\"\"\"\n",
    "\n",
    "# Now when we call finditer() we just pass the re.VERBOSE flag as the last parameter, this makes it much\n",
    "# easier to understand large regexes!\n",
    "for item in re.finditer(pattern,wiki,re.VERBOSE):\n",
    "    # We can get the dictionary returned for the item with .groupdict()\n",
    "    print(item.groupdict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: New York Times and Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's another example from the New York Times which covers health tweets on news items. This data came from\n",
    "# the UC Irvine Machine Learning Repository which is a great source of different kinds of data\n",
    "with open(\"datasets/nytimeshealth.txt\",\"r\") as file:\n",
    "    # We'll read everything into a variable and take a look at it\n",
    "    health=file.read()\n",
    "health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So here we can see there are tweets with fields separated by pipes |. Lets try and get a list of all of the\n",
    "# hashtags that are included in this data. A hashtag begins with a pound sign (or hash mark) and continues\n",
    "# until some whitespace is found\n",
    "\n",
    "# So lets create a pattern. We want to include the hash sign first, then any number of alphanumeric\n",
    "# characters. And we end when we see some whitespace\n",
    "pattern = '#[\\w\\d]*(?=\\s)'\n",
    "\n",
    "# Notice that the ending is a look ahead. We're not actually interested in matching whitespace in the return\n",
    "# value. Also notice that I use an asterix * instead of the plus + for the matching of alphabetical characters\n",
    "# or digits, because a + would require at least one of each\n",
    "\n",
    "# Lets searchg and display all of the hashtags\n",
    "re.findall(pattern, health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see here that there were lots of ebola related tweeks in this particular dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lecture has been an overview of regular expressions, and really, we've just scratched the surface of what  you can do. Now, I actually find regex's really frustrating - they're incredibly powerful, but if you don't use them for a while you're left grasping for memory of some of the details, especially named groups and look ahead searches. But, there are lots of great examples and reference guides on the web, including the python documentation for regex, and with these in hand you should be able to write concise and readable code which performs well too. Having basic regex literacy is a core skill for applied data scientists."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
