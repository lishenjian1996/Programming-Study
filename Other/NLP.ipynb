{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\lishe\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Score: {'neg': 0.014, 'neu': 0.83, 'pos': 0.156, 'compound': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "# 下载 VADER 词典\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "# 初始化情感分析工具\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# 打开 PDF 文件并提取文本\n",
    "pdf_path = r\"C:\\Users\\lishe\\Documents\\GitHub\\Programming-Study\\Other\\AllianceBernstein Holding L.P. Limited Partnership Units (AB) Q3 2024 Earnings Call Transcript _ Seeking Alpha.pdf\"\n",
    "text = \"\"\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "# 进行情感分析\n",
    "sentiment_score = sia.polarity_scores(text)\n",
    "\n",
    "# 输出情感分析结果\n",
    "print(\"Sentiment Score:\", sentiment_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lishe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text (First 1000 characters): Transcripts\n",
      "AllianceBernstein Holding L.P. Limited Partnership\n",
      "Units (AB) Q\u0000 \u0000\u0000\u0000\u0000 Earnings Call Transcript\n",
      "Oct. \u0000\u0000, \u0000\u0000\u0000\u0000 \u0000:\u0000\u0000 PM ET | AllianceBernstein Holding L.P. Limited Partnership Units (AB) Stock\n",
      "SA Transcripts\n",
      "\u0000\u0000\u0000.\u0000\u0000K Followers\n",
      "Q\u0000: \u0000\u0000\u0000\u0000-\u0000\u0000-\u0000\u0000 Earnings Summary\n",
      "Play Call Press Release \u0000\u0000-Q\n",
      "EPS of $\u0000.\u0000\u0000 beats by $\u0000.\u0000\u0000 | Revenue of $\u0000\u0000\u0000.\u0000\u0000M (-\u0000.\u0000\u0000% Y/Y) beats by $\u0000.\u0000\u0000M\n",
      "AllianceBernstein Holding L.P. Limited Partnership Units (NYSE:AB) Q\u0000 \u0000\u0000\u0000\u0000 Earnings Conference Call October \u0000\u0000,\n",
      "\u0000\u0000\u0000\u0000 \u0000\u0000:\u0000\u0000 AM ET\n",
      "Company ParticipantsSeth Bernstein - President and CEO\n",
      "Jackie Marks - CFO\n",
      "Onur Erzan - Head of Global Client Group and Private Wealth\n",
      "Matt Bass - Head of Private Alternatives\n",
      "Conference Call Participants\n",
      "Ben Budish - Barclays\n",
      "Robin Holby - TD Cowen\n",
      "Craig Siegenthaler - Bank of America\n",
      "John Dunn - Evercore ISI\n",
      "Rick Roy - Jefferies\n",
      "Operator\n",
      "Ladies and gentlemen, thank you for standing by and welcome to the AllianceBernstein Third Quarter \u0000\u0000\u0000\u0000 Earnings\n",
      "Review. At this time, all participants are\n",
      "Matched Positive Words: []\n",
      "Matched Negative Words: []\n",
      "Matched Uncertainty Words: []\n",
      "Matched Constraining Words: []\n",
      "Sentiment Score: {'Positive': 0, 'Negative': 0, 'Uncertainty': 0, 'Constraining': 0}\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# 下载所需的词形还原数据集\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# 加载 Loughran-McDonald 词典\n",
    "file_path = r'C:\\Users\\lishe\\Documents\\GitHub\\Programming-Study\\Other\\Loughran-McDonald_MasterDictionary_1993-2023.csv'\n",
    "lm_dict = pd.read_csv(file_path)\n",
    "\n",
    "# 将词典分为多个情感类别\n",
    "positive_words = set(lm_dict[lm_dict['Positive'] == 1]['Word'].str.lower())\n",
    "negative_words = set(lm_dict[lm_dict['Negative'] == 1]['Word'].str.lower())\n",
    "uncertainty_words = set(lm_dict[lm_dict['Uncertainty'] == 1]['Word'].str.lower())\n",
    "constraining_words = set(lm_dict[lm_dict['Constraining'] == 1]['Word'].str.lower())\n",
    "\n",
    "# 初始化词形还原器\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# 情感分析函数\n",
    "def analyze_sentiment(text):\n",
    "    # 将文本转换为小写并分词\n",
    "    words = text.lower().split()\n",
    "    # 词形还原\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    word_counts = Counter(lemmatized_words)\n",
    "\n",
    "    # 记录匹配的词汇\n",
    "    matched_words = {\n",
    "        \"Positive\": [word for word in lemmatized_words if word in positive_words],\n",
    "        \"Negative\": [word for word in lemmatized_words if word in negative_words],\n",
    "        \"Uncertainty\": [word for word in lemmatized_words if word in uncertainty_words],\n",
    "        \"Constraining\": [word for word in lemmatized_words if word in constraining_words]\n",
    "    }\n",
    "\n",
    "    # 打印匹配的词汇\n",
    "    print(\"Matched Positive Words:\", matched_words[\"Positive\"])\n",
    "    print(\"Matched Negative Words:\", matched_words[\"Negative\"])\n",
    "    print(\"Matched Uncertainty Words:\", matched_words[\"Uncertainty\"])\n",
    "    print(\"Matched Constraining Words:\", matched_words[\"Constraining\"])\n",
    "\n",
    "    # 计算每类情感词汇的频率\n",
    "    sentiment_counts = {\n",
    "        \"Positive\": len(matched_words[\"Positive\"]),\n",
    "        \"Negative\": len(matched_words[\"Negative\"]),\n",
    "        \"Uncertainty\": len(matched_words[\"Uncertainty\"]),\n",
    "        \"Constraining\": len(matched_words[\"Constraining\"])\n",
    "    }\n",
    "    \n",
    "    return sentiment_counts\n",
    "\n",
    "# 打开并提取 PDF 文本\n",
    "pdf_path = r'C:\\Users\\lishe\\Documents\\GitHub\\Programming-Study\\Other\\AllianceBernstein Holding L.P. Limited Partnership Units (AB) Q3 2024 Earnings Call Transcript _ Seeking Alpha.pdf'\n",
    "text = \"\"\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "# 检查提取的文本\n",
    "print(\"Extracted Text (First 1000 characters):\", text[:1000])  # 打印前1000个字符，确保提取了正确的内容\n",
    "\n",
    "# 进一步清理文本（可选）：去除标点符号\n",
    "import re\n",
    "text = re.sub(r'[^\\w\\s]', '', text)  # 去除标点符号\n",
    "\n",
    "# 对提取的文本进行情感分析\n",
    "sentiment_score = analyze_sentiment(text)\n",
    "\n",
    "# 输出情感分析结果\n",
    "print(\"Sentiment Score:\", sentiment_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lishe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Positive Words: []\n",
      "Matched Negative Words: []\n",
      "Matched Uncertainty Words: []\n",
      "Matched Constraining Words: []\n",
      "Total Sentiment Score: {'Positive': 0, 'Negative': 0, 'Uncertainty': 0, 'Constraining': 0}\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# 下载所需的词形还原数据集\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# 加载 Loughran-McDonald 词典\n",
    "file_path = r'C:\\Users\\lishe\\Documents\\GitHub\\Programming-Study\\Other\\Loughran-McDonald_MasterDictionary_1993-2023.csv'\n",
    "lm_dict = pd.read_csv(file_path)\n",
    "\n",
    "# 将词典分为多个情感类别\n",
    "positive_words = set(lm_dict[lm_dict['Positive'] == 1]['Word'].str.lower())\n",
    "negative_words = set(lm_dict[lm_dict['Negative'] == 1]['Word'].str.lower())\n",
    "uncertainty_words = set(lm_dict[lm_dict['Uncertainty'] == 1]['Word'].str.lower())\n",
    "constraining_words = set(lm_dict[lm_dict['Constraining'] == 1]['Word'].str.lower())\n",
    "\n",
    "# 初始化词形还原器\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# 情感分析函数\n",
    "def analyze_sentiment(text):\n",
    "    words = text.lower().split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    word_counts = Counter(lemmatized_words)\n",
    "\n",
    "    # 记录匹配的词汇\n",
    "    matched_words = {\n",
    "        \"Positive\": [word for word in lemmatized_words if word in positive_words],\n",
    "        \"Negative\": [word for word in lemmatized_words if word in negative_words],\n",
    "        \"Uncertainty\": [word for word in lemmatized_words if word in uncertainty_words],\n",
    "        \"Constraining\": [word for word in lemmatized_words if word in constraining_words]\n",
    "    }\n",
    "\n",
    "    # 打印匹配的词汇\n",
    "    print(\"Matched Positive Words:\", matched_words[\"Positive\"])\n",
    "    print(\"Matched Negative Words:\", matched_words[\"Negative\"])\n",
    "    print(\"Matched Uncertainty Words:\", matched_words[\"Uncertainty\"])\n",
    "    print(\"Matched Constraining Words:\", matched_words[\"Constraining\"])\n",
    "\n",
    "    # 计算每类情感词汇的频率\n",
    "    sentiment_counts = {\n",
    "        \"Positive\": len(matched_words[\"Positive\"]),\n",
    "        \"Negative\": len(matched_words[\"Negative\"]),\n",
    "        \"Uncertainty\": len(matched_words[\"Uncertainty\"]),\n",
    "        \"Constraining\": len(matched_words[\"Constraining\"])\n",
    "    }\n",
    "    \n",
    "    return sentiment_counts\n",
    "\n",
    "# 打开并提取 PDF 文本\n",
    "pdf_path = r'C:\\Users\\lishe\\Documents\\GitHub\\Programming-Study\\Other\\AllianceBernstein Holding L.P. Limited Partnership Units (AB) Q3 2024 Earnings Call Transcript _ Seeking Alpha.pdf'\n",
    "text = \"\"\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + \" \"\n",
    "\n",
    "# 将文本分段，并仅选择一定长度的段落\n",
    "paragraphs = text.split('\\n\\n')\n",
    "filtered_paragraphs = [p for p in paragraphs if len(p.split()) > 50]  # 筛选字数超过50的段落\n",
    "\n",
    "# 逐段进行情感分析\n",
    "total_sentiment = {\"Positive\": 0, \"Negative\": 0, \"Uncertainty\": 0, \"Constraining\": 0}\n",
    "for paragraph in filtered_paragraphs:\n",
    "    cleaned_paragraph = re.sub(r'[^\\w\\s]', '', paragraph)  # 去除标点符号\n",
    "    sentiment_score = analyze_sentiment(cleaned_paragraph)\n",
    "    # 累加情感分数\n",
    "    for key in total_sentiment:\n",
    "        total_sentiment[key] += sentiment_score[key]\n",
    "\n",
    "# 输出总的情感分析结果\n",
    "print(\"Total Sentiment Score:\", total_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph 1: Transcripts\n",
      "AllianceBernstein Holding L.P. Limited Partnership\n",
      "Units (AB) Q\u0000 \u0000\u0000\u0000\u0000 Earnings Call Transcript\n",
      "Oct. \u0000\u0000, \u0000\u0000\u0000\u0000 \u0000:\u0000\u0000 PM ET | AllianceBernstein Holding L.P. Limited Partnership Units (AB) Stoc...\n"
     ]
    }
   ],
   "source": [
    "for i, paragraph in enumerate(filtered_paragraphs):\n",
    "    print(f\"Paragraph {i+1}: {paragraph[:200]}...\")  # 仅打印段落前200字符\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正面情绪词数量: 116\n",
      "负面情绪词数量: 55\n",
      "中性情绪词数量: 7630\n",
      "正面情绪词比例: 1.49%\n",
      "负面情绪词比例: 0.71%\n",
      "中性情绪词比例: 97.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lishe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import fitz  # PyMuPDF\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# 从PDF提取文本的函数\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(pdf_path) as pdf:\n",
    "        for page_num in range(pdf.page_count):\n",
    "            page = pdf[page_num]\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# 加载Loughran-McDonald情感词典，提取“Word”和情绪标记列\n",
    "lm_dict = pd.read_csv(r'C:\\Users\\lishe\\Documents\\GitHub\\Programming-Study\\Other\\Loughran-McDonald_MasterDictionary_1993-2023.csv')\n",
    "\n",
    "# 选择正面和负面词\n",
    "positive_words = set(lm_dict[lm_dict['Positive'] > 0]['Word'].str.lower())\n",
    "negative_words = set(lm_dict[lm_dict['Negative'] > 0]['Word'].str.lower())\n",
    "\n",
    "# 从PDF中提取电话会议文本\n",
    "pdf_path = r'C:\\Users\\lishe\\Documents\\GitHub\\Programming-Study\\Other\\AllianceBernstein Holding L.P. Limited Partnership Units (AB) Q3 2024 Earnings Call Transcript _ Seeking Alpha.pdf'\n",
    "text = extract_text_from_pdf(pdf_path).lower()  # 转为小写\n",
    "tokens = word_tokenize(re.sub(r'\\W+', ' ', text))  # 去除标点并分词\n",
    "\n",
    "# 统计情绪词频\n",
    "total_words = len(tokens)\n",
    "positive_count = sum(1 for word in tokens if word in positive_words)\n",
    "negative_count = sum(1 for word in tokens if word in negative_words)\n",
    "neutral_count = total_words - (positive_count + negative_count)\n",
    "\n",
    "# 计算情绪比例\n",
    "positive_ratio = (positive_count / total_words) * 100\n",
    "negative_ratio = (negative_count / total_words) * 100\n",
    "neutral_ratio = (neutral_count / total_words) * 100\n",
    "\n",
    "# 输出统计结果\n",
    "print(\"正面情绪词数量:\", positive_count)\n",
    "print(\"负面情绪词数量:\", negative_count)\n",
    "print(\"中性情绪词数量:\", neutral_count)\n",
    "print(\"正面情绪词比例: {:.2f}%\".format(positive_ratio))\n",
    "print(\"负面情绪词比例: {:.2f}%\".format(negative_ratio))\n",
    "print(\"中性情绪词比例: {:.2f}%\".format(neutral_ratio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
